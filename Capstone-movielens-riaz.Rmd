---
title: "Capstone Movie recommendation project"
author: "Riaz Mohamed Vellamparambil"
date: 12/16/2021
output: html_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction
The goal of this project is to build a movie recommendation system using machine learning.In this project, we will explore and visualize the MovieLens dataset that consists of over 10 million film ratings. We will develop an ML model by creating both training and test sets to predict movie ratings on a validation set that results in an RMSE or Root Mean Square Error of less than .87750. <br>
The root-mean-square deviation (RMSD) or root-mean-square error (RMSE) is a frequently used measure of the differences between values (sample or population values) predicted by a model or an estimator and the values observed

# Dataset

GroupLens Research has collected and made available rating data sets from the MovieLens website ( https://movielens.org). The data sets were collected over various periods of time, depending on the size of the set. titled "MovieLens," was developed by researchers at the University of Minnesota and was designed to generate personalized film recommendations. For this project, the 10M version will be used. It contains 10 million ratings on 10,000 movies by 72,000 users. It was released in 2009.

# Steps of Analysis

* **Data Preparation** - We will load the data, split the dataset into edx and validation sets. We will then create a train and test set.
* **Data Exploration** - We will explore the data, plot histograms, create tables and graphs to observe what attributes of the dataset that affect ratings.
* **Modeling** - Once we determine the biases, we will apply these biases to our models to determine the RMSE we expect to achieve.
* **Validation** - Validate our model against the validation set

# Data Preparation

**Install and load libraries and MovieLens Dataset** 
To install the required packages, we use if(!require and load the packages from http://cran.us.r-project.org. Load Libraries and the MovieLens dataset



```{r message=FALSE, warning=FALSE}

# Install all needed libraries 

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(forcats)) install.packages("forcats", repos = "http://cran.us.r-project.org")
if(!require(ggplot2)) install.packages("ggplot2", repos = "http://cran.us.r-project.org")
if(!require(kableExtra)) install.packages("kableExtra" , repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(tidyr)) install.packages("tidyr", repos = "http://cran.us.r-project.org")
if(!require(stringr)) install.packages("stringr", repos = "http://cran.us.r-project.org")
if(!require(plotly)) install.packages("plotly", repos = "http://cran.us.r-project.org")
if(!require(ggthemes)) install.packages("ggthemes", repos = "http://cran.us.r-project.org")

# Load required libraries

library(tidyverse)
library(caret)
library(kableExtra)
library(data.table)
library(dplyr)
library(tidyverse)
library(tidyr)
library(stringr)
library(forcats)
library(ggplot2)
library(plotly)
library(ggthemes)
# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

# if using R 4.0 or later:
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           title = as.character(title),
                                           genres = as.character(genres))


movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.5 or earlier, use `set.seed(1)`
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)

```

**View the edx Dataset** 

```{r}
edx %>% as_tibble()
```

**View the edx Dataset** 

We have split the original dataset into the edx and validation sets. We will now split the edx set into two (test and train). These sets will be used to both build and test our algorithm. We will test the accuracy of the results with a validation set

```{r message=FALSE, warning=FALSE}

set.seed(1, sample.kind="Rounding")

# create a test & train set

test_index <- createDataPartition(y = edx$rating, times = 1, p = 0.1, list = FALSE)
train <- edx[-test_index,]
temp <- edx[test_index,]

# Matching userId and movieId in both train and test sets
test <- temp %>% 
  semi_join(train, by = "movieId") %>%
  semi_join(train, by = "userId")

# Add rows baqck into the train set
removed <- anti_join(temp, test)
train <- rbind(train, removed)

rm(removed, temp, test_index)

```

# Data Exploration 

**View the train Dataset** 

* Let us explore the train data set

```{r warning=FALSE}
train %>% as_tibble()
```

**Conclusion:** We see from the table that the same user has rated multiple movies.


* Let us check the unique set from the train set

```{r warning=FALSE}
train %>% summarize(
  users=n_distinct(userId),
  movies=n_distinct(movieId),
  minRating=min(rating), 
  maxRating=max(rating) 
)
```

**Conclusion:** We see 69878 users and 10677 unique movies with a rating between 0.5 to 5. We also know that the same users have rated many movies, hence there may be movies that users haven’t rated and users who have not rated any movies. From this, we understand that this set contains many NA values as well.

***RATINGS EFFECT***: <br><br><br> Let us check the top 10 movie ratings by the number of ratings and an average rating

```{r warning=FALSE}
edx %>% group_by(title) %>%
  summarize(avgRating = mean(rating),numberOfRatings = n()) %>%
  arrange(desc(avgRating)) %>%
  top_n(10, wt=avgRating)
```

**Conclusion:** Are these movies the highly rated movies?  The top 5 have only 1 rating. To determine the highest rated movies, we need at an average a higher number of polls for the movie itself

* Let us take the top 10 Rated movies which have at the least 500 ratings

```{r warning=FALSE}
edx %>% group_by(title) %>%
  summarize(numberOfRatings = n(), avgRating = mean(rating)) %>%
  filter(numberOfRatings > 500) %>%
  arrange(desc(avgRating)) %>%
  top_n(10, wt=avgRating)
```

**Conclusion:** The most popular movies have higher number of ratings 

* Distribution of Ratings : We will now analyze the distribution of ratings vs number of ratings

```{r warning=FALSE}
ratingDist <- ggplot(edx, aes(rating, fill = cut(rating, 100))) + 
  geom_histogram(color = "blue", binwidth = 0.2) + scale_x_continuous(breaks = seq(0.5, 5, 0.5)) + 
  labs(title = "Rating distrubution of movies", x = "Ratings", y = "No Of Rating") + 
  theme(axis.text = element_text(size = 10), 
  plot.title = element_text(size = 11, color = "red", hjust = 0.25)) 
  

ggplotly(ratingDist)
```

**Conclusion:** The histogram confirms most viewers tend to rate a movie on an average at 3 or above.


***GENRE EFFECT***: <br><br><br>	We will now analyze if the genre of a movie line up with ratings and the number of ratings being rated

```{r message=FALSE, warning=FALSE}

edx_genres <-edx %>% separate_rows(genres, sep = "\\|")

edx_genres %>%as_tibble()

edx_genres %>%
  group_by(genres) %>% summarize(Ratings_Sum = n(), Average_Rating = mean(rating)) %>%
  arrange(-Ratings_Sum)

edx_genres %>%as_tibble()

```

```{r warning=FALSE}

edx_genres %>%
  group_by(genres) %>% summarize(Ratings_Sum = n(), avgRating = mean(rating)) %>%
  arrange(-avgRating)

```

**Conclusion:** The histogram confirms most viewers tend to rate a movie on an average at 3 or above.

**Visual representation**: Sum of Movie Ratings per Genre

```{r message=FALSE, warning=FALSE}
edx$genres <-as.factor(edx$genres)
edx_genres$genres <-as.factor(edx_genres$genres)
```

```{r warning=FALSE}
genres_ratings_edx <-edx_genres %>% group_by(genres) %>% summarize(Ratings_Sum = n())
genres_ratings_edx %>% ggplot(aes(x = Ratings_Sum , y = reorder(genres, Ratings_Sum)))+
  ggtitle("Distribution")+
  xlab("Sum of Ratings")+
  ylab("Genres")+
  geom_bar(stat = "identity",  fill = "orange", color = "black")+
  theme(plot.title = element_text(hjust = 1.0))
```

**Conclusion:** The number of ratings for the first four-five highly rated genres has fewer ratings and hence some of these can skew data as well. We also have some false Genres

* Let us analyze the mean Rating per genre

```{r warning=FALSE}
genres_mean_ratings_edx <-edx_genres %>% group_by(genres) %>% summarize(avg_rating = mean(rating)) %>%
  arrange(-avg_rating)
genres_mean_ratings_edx %>% ggplot(aes(x = reorder(genres, avg_rating), y = avg_rating))+
  ggtitle("Mean Rating by Genre")+
  xlab("Genres")+
  ylab("Mean Rating")+
  coord_flip()+
  theme(plot.title = element_text(hjust = 0.5))+
  geom_bar(stat = "identity",  fill = "orange", color = "black")
```

**Conclusion:** Average ratings for genres are between 3 and 4. Genre doesn’t affect ratings.



***Age of Movie Effect***: <br><br><br>	We will now analyze if the genre of a movie line up with ratings and the number of ratings being rated  <br>

To understand the effects of time (age of a movie) on ratings, we will require to convert the timestamps to years and then look at the affect

* Convert timestamps to the year of rating, we will do the same conversions for all our datasets (edx, validation , train, and test)

```{r warning=FALSE}

edx <- edx %>% mutate(timestamp = format(as.POSIXct(timestamp, origin = "1970-01-01", 
                                          tz = Sys.getenv("TZ")),"%Y"))
names(edx)[names(edx) == "timestamp"] <- "RatingYear"
head(edx)

```

```{r message=FALSE, warning=FALSE}
# Let us do the same for the validation set

validation <- validation %>% mutate(timestamp = format(as.POSIXct(timestamp, origin = "1970-01-01", 
                                                                  tz = Sys.getenv("TZ")),"%Y"))
names(validation)[names(validation) == "timestamp"] <- "RatingYear"
head(validation)


# We will have to do the same for the train and testg sets

train <- train %>% mutate(timestamp = format(as.POSIXct(timestamp, origin = "1970-01-01", 
                                                        tz = Sys.getenv("TZ")),"%Y"))
names(train)[names(train) == "timestamp"] <- "RatingYear"
head(train)

test <-test %>% mutate(timestamp = format(as.POSIXct(timestamp, origin = "1970-01-01", 
                                                     tz = Sys.getenv("TZ")),"%Y"))
names(test)[names(test) == "timestamp"] <- "RatingYear"
head(test)

```

* To get a sense of the time frame of the ratings we can use the range function

```{r warning=FALSE}

range(edx$RatingYear)

```

**Conclusion:** A look at the range seems to point out that all movies have been rated between 1995-2009

* Visual Representation: A look at the range seems to point out that all movies have been rated between 1995-2009

```{r message=FALSE, warning=FALSE}
edx$RatingYear <-as.numeric(edx$RatingYear)
str(edx)
```

```{r warning=FALSE}

edx %>% ggplot(aes(RatingYear))+
  geom_histogram(fill = "blue", color = "black", bins = 35)+
  ggtitle("User Distribution")+
  xlab("Rating Year")+
  ylab("No of Users")+
  theme(plot.title = element_text(hjust = 0.5))


```

**Conclusion:** 1996, 2000 and 2005 have the highest user rating

* To find the age of a movie we will need to find the year it was released. The release year of the movie is part of the title


```{r warning=FALSE}

edx %>%as_tibble()

```

* Cerate a new column in the dataset to have a yearReleased





```{r message=FALSE, warning=FALSE}
# To find the age of a movie we will need to first find the year it was released. The release year of the movie is 
# in the title

premierDate <- stringi::stri_extract(edx$title, regex = "(\\d{4})", comments = TRUE ) %>% as.numeric()
edx <- edx %>% mutate(yearReleased = premierDate)
head(edx)
```


```{r warning=FALSE}

# The Issue with this is if there was a four digit number in the movie title then that will be taken, can 
# we see if this can be solved in an any other way
yearPremierDate <-as.numeric(str_sub(edx$title, start = -5, end = -2))
edx <- edx %>% mutate(yearReleased = yearPremierDate)
head(edx)

```


* Let us do the same for the other datasets we have


```{r message=FALSE, warning=FALSE}
# Let us do the same for the validation set

validationPremierDate <-as.numeric(str_sub(validation$title, start = -5, end = -2))
validation <- validation %>% mutate(yearReleased = validationPremierDate)
head(validation)


# We will have to do the same for the train and test sets

trainPremierDate <- as.numeric(str_sub(train$title, start = -5, end = -2))
train <- train %>% mutate(yearReleased = trainPremierDate)
head(train)

testPremierDate <- as.numeric(str_sub(test$title, start = -5, end = -2))
test <- test %>% mutate(yearReleased = testPremierDate)
head(test)


# Movie age will be the current year minus the premierReleaseYear

edx <-edx %>% mutate(age_of_movie = 2021 - yearReleased)
validation <-validation %>% mutate(age_of_movie = 2021 - yearReleased)
train <-train %>% mutate(age_of_movie = 2021 - yearReleased)
test <-test %>% mutate(age_of_movie = 2021 - yearReleased)


summary(edx$age_of_movie)
summary(validation$age_of_movie)
summary(train$age_of_movie)

```

**Visual Representation:** Let us check if the age of a movie affects the movie ratings

```{r warning=FALSE}

edx %>% group_by(age_of_movie) %>% summarize(avg_movie_rating = mean(rating)) %>% 
  ggplot(aes(age_of_movie, avg_movie_rating))+
  ggtitle("Age of Movie & Average Movie Rating")+
  xlab("Age of Movie")+
  ylab("Avg Movie Rating")+
  geom_smooth(method = "gam")+
  geom_point(color = "honeydew")+
  theme(plot.title = element_text(hjust = 0.5))


```

**Conclusion:** We see the longer the movie is there, there are more ratings as well as some of the highly-rated movies are there longer. This seems to be a positive effect.


**Data Exploration Conclusion:** We observe three factors that affect ratings of a movie , the movie itself (some movies are rated higher than others), users and the age of the movie. We will base our modeling on the three biases.


# Modeling <br><br>
From the above analysis, we know that the number of users, age of the movie seems to influence the overall ratings.

**RMSE** 

The root-mean-square deviation (RMSD) or root-mean-square error (RMSE) is a frequently used measure of the differences between values (sample or population values) predicted by a model or an estimator and the values observed

RMSE :  function(true_ratings, predicted_ratings)
{
  	sqrt(mean((true_ratings - predicted_ratings)^2))
}
 
**Naive Baseline Model**

The simplest model that can be built is a Naïve model that predicts the mean always. For the first model, we will predict the same rating for all movies. Here no bias is considered. This method confirms to a linear equation <br> <br>

Y u,i = Mu + E u,i .   Where E u,i = independent errors centered at 0

```{r warning=FALSE}
mean_train_mu <-mean(train$rating)
naivermse <- RMSE(test$rating, mean_train_mu)
naivermse
```



```{r warning=FALSE}
## Save Results in Data Frame
rmse_results = data_frame(method = "Naive Analysis by Mean", RMSE = naivermse)
rmse_results %>% knitr::kable(., format = "pipe", padding = 2)

```

**Conclusion:** Naive RMSE : **1.060054**

**Median Model**

Let us  include the median or any other random number. The method confirms to a linear equation  <br>
Y u,i = Median + E u,i  Where  Y u,i is the predicted rating  E u,i = independent errors centered at 0

```{r warning=FALSE}
median_train_mu <-median(train$rating)
medianrmse <-RMSE(test$rating, median_train_mu)
medianrmse

```

```{r warning=FALSE}
rmse_results <- bind_rows(rmse_results, 
                          data_frame(method="Analysis By Median",
                                     RMSE = medianrmse))
rmse_results %>% knitr::kable(., format = "pipe", padding = 2)

```

**Conclusion:** Median RMSE : **1.166756**

**Movie Bias Model**

From our data exploration, we know that some movies are rated more than others. So let us add another bias for movie effect <br>

Y u,i = Mu + Movie Bias + E u,i where  Y u,i is the predicted rating  E u,i = independent errors centered at 0 Mu = Average Rating


Create a prediction

```{r message=FALSE, warning=FALSE}

movieBias <- train %>% group_by(movieId) %>%
  summarize(mean_rating_m = mean(rating - mean_train_mu))


# Create the Prediction
prediction_mov_eff <-mean_train_mu + test %>% 
  left_join(movieBias, by = "movieId") %>% .$mean_rating_m



```

```{r warning=FALSE}
moviermse <-RMSE(test$rating, prediction_mov_eff)
moviermse

```


```{r warning=FALSE}
rmse_results <- bind_rows(rmse_results, 
                          data_frame(method="Analysis By Movie Bias",
                                     RMSE = moviermse))
rmse_results %>% knitr::kable(., format = "pipe", padding = 2)

```

**Conclusion:** Movie Bias RMSE: **0.9429615**. When we add movie bias to the equation the RMSE decreases but the model is not yet effective.


**Movie and User Bias Model**

From our data exploration we know that some movies are rated more than others, users also affect the ratings of the movie. So let us add another bias to the above which is the user bias <br> <br>

Y u,i = Mu + Movie Bias + User Bias + E u,i where  <br>
Y u,i is the predicted rating  <br>
E u,i = independent errors centered at 0 <br>
Mu = Average Rating <br>



Create a prediction <br>

```{r message=FALSE, warning=FALSE}
# Now let us introduce users to the above. This is the user bias where users can rate movies as per their interest
# The equation for predicted rating Y u,i = Mu + Movie Bias + User Bias + E u,i (Mu -- Mean ratging and  E u,i Independent Error)


movieUserBias <- train %>% left_join(movieBias, by = "movieId") %>% group_by(userId) %>%
  summarize(mean_rating_m_u = mean(rating - mean_train_mu - mean_rating_m))


# Create the Prediction
prediction_mov_usr_eff <-test %>% left_join(movieBias, by = "movieId") %>%
  left_join(movieUserBias, by = "userId") %>%
  mutate(predictions = mean_train_mu + mean_rating_m + mean_rating_m_u) %>% .$predictions
```

```{r warning=FALSE}
movie_usr_rmse <-RMSE(test$rating, prediction_mov_usr_eff)
movie_usr_rmse

```


```{r warning=FALSE}
rmse_results <- bind_rows(rmse_results, 
                          data_frame(method="Analysis By Movie  & User Bias",
                                     RMSE = movie_usr_rmse))
rmse_results %>% knitr::kable(., format = "pipe", padding = 2)

```

**Conclusion:** Movie and User Bias RMSE: **0.8646843** When we add user bias to the equation the RMSE decreases and meets our target RMSE.

**Movie , User and Age of Movie Bias Model**

Now let us introduce the movie age to the above. This is the movie age bias where the more the number of years the more the number of ratings <br>

Y u,i = Mu + Movie Bias + User Bias + Movie Age Bias + E u,i <br>
where <br>
Y u,i is the predicted rating  <br>
E u,i = independent errors centered at 0 <br>
Mu = Average Rating <br>


Create a prediction <br>

```{r message=FALSE, warning=FALSE}
movieUserAgeBias <- train %>% left_join(movieBias, by = "movieId") %>% left_join(movieUserBias, by = "userId") %>%
  group_by(age_of_movie) %>% 
  summarize(mean_rating_m_u_a = mean(rating - mean_rating_m_u - mean_rating_m - mean_train_mu ))
  

# Create the Prediction
prediction_mov_usr_mage_eff <-test %>% left_join(movieBias, by = "movieId") %>%
  left_join(movieUserBias, by = "userId") %>% left_join(movieUserAgeBias, by = "age_of_movie") %>%
  mutate(predictions = mean_train_mu + mean_rating_m + mean_rating_m_u  + mean_rating_m_u_a) %>% .$predictions
```

```{r warning=FALSE}
movie_usr_mage_rmse <-RMSE(test$rating, prediction_mov_usr_mage_eff)
movie_usr_mage_rmse
```

**Conclusion:** Movie User and Age of Movie Bias RMSE: **0.8643301**. The movie age has a small difference in the RMSE

```{r warning=FALSE}
rmse_results <- bind_rows(rmse_results, 
                          data_frame(method="Analysis By Movie, User & Movie Age Bias",
                                     RMSE = movie_usr_mage_rmse))
rmse_results %>% knitr::kable(., format = "pipe", padding = 2)

```


**Conclusion:** We have observed that there was a decrease in rmse when we had both movie and user bias when we added age to the equation there was very little difference.


#Regularization

Regularization allows for reduced errors caused by movies with few ratings which can influence the prediction and skew the error metric. The method uses a tuning parameter, lambda, to minimize the RMSE. Modifying movie bias and user bias for movies with limited ratings.

**Movie & User Bias Model with Regularization**

Adding a tuning parameter lambda to the model

```{r message=FALSE, warning=FALSE}
# lambdas is a tuning parameter. We can use cross-validation to choose it
# Movie & User Bias Model with Regularization
lambdas <- seq(0, 10, 0.25)
rmses <- sapply(lambdas, function(l){
  
  train_mu <- mean(train$rating)
  
  movie_bias_i <- train %>%
    group_by(movieId) %>%
    summarise(movie_bias_i = sum(rating - train_mu)/(n()+l))
  
  user_bias_u <- train %>%
    left_join(movie_bias_i, by="movieId") %>%
    group_by(userId) %>%
    summarise(user_bias_u = sum(rating - movie_bias_i - train_mu)/(n()+l))
  
  predicted_ratings <- test %>%
    left_join(movie_bias_i, by = "movieId") %>%
    left_join(user_bias_u, by = "userId") %>%
    mutate(predictions = train_mu + movie_bias_i + user_bias_u) %>%.$predictions

  
  return(RMSE(predicted_ratings, test$rating))
})
```

```{r warning=FALSE}
qplot(lambdas, rmses)  
```

**Conclusion:** The RMSE is minimum when the lambda is 5

```{r warning=FALSE}
rmse_regularisation <- min(rmses)
rmse_regularisation
```

```{r warning=FALSE}
rmse_results <- bind_rows(rmse_results, 
                          data_frame(method="Movie and User Effect with Regularization",
                                     RMSE = rmse_regularisation))
rmse_results %>% knitr::kable(., format = "pipe", padding = 2)
```

**Conclusion:** Movie and User Bias RMSE with regularization results is 0.8641362.


# Validation

**Naive Baseline Model**

The simplest model that can be built is a Naïve model that predicts the mean always. For the first model, we will predict the same rating for all movies. Here no bias is considered. This method confirms to a linear equation <br>

Y u,i = Mu + E u,i .  <br>
Where E u,i = independent errors centered at 0  <br>


Validate our model against the validation set 


```{r warning=FALSE}
mean_validation_mu <-mean(edx$rating)
naivermse_val <- RMSE(validation$rating, mean_validation_mu)
naivermse_val
```

```{r warning=FALSE}
## Save Results in Data Frame
rmse_results_val = data_frame(Method= "Naive Analysis by Mean", ValidationSet_RMSE = naivermse_val)
rmse_results_val %>% knitr::kable(., format = "pipe", padding = 2)
```

**Conclusion:** Naive RMSE : **1.061202**


**Median Model**
Let’s include the median or any other random number. The method confirms to a linear equation <br>
Y u,i = Median + E u,i <br>
where <br>
Y u,i is the predicted rating <br>
E u,i = independent errors centered at 0<br>



```{r warning=FALSE}
median_validation_mu <-median(edx$rating)
medianrmse_val <-RMSE(validation$rating, median_validation_mu)
medianrmse_val


```

```{r warning=FALSE}
## Save Results in Data Frame

rmse_results_val <- bind_rows(rmse_results_val, 
                          data_frame(Method="Analysis By Median",
                                     ValidationSet_RMSE = medianrmse_val))
rmse_results_val %>% knitr::kable(., format = "pipe", padding = 2)
```


**Conclusion:** Median RMSE: **1.168016**

**Movie Bias Model**

From our data exploration we know that some movies are rated more than others. So let us add another bias for movie effect 

Y u,i = Mu + Movie Bias + E u,i  <br>
where <br>
Y u,i is the predicted rating <br>
E u,i = independent errors centered at 0 <br>
Mu = Average Rating<br>

Validate our model against the validation set <br>


Create a prediction:<br>

```{r warning=FALSE}
movieBias_val <- edx %>% group_by(movieId) %>%
  summarize(mean_rating_m_val = mean(rating - median_validation_mu))


# Create the Prediction
prediction_mov_eff_val <-median_validation_mu + validation %>% 
  left_join(movieBias_val, by = "movieId") %>% .$mean_rating_m_val
moviermse_val <-RMSE(validation$rating, prediction_mov_eff_val)
moviermse_val

```

```{r warning=FALSE}
## Save Results in Data Frame


rmse_results_val <- bind_rows(rmse_results_val, 
                          data_frame(Method="Analysis By Movie Bias",
                                     ValidationSet_RMSE = moviermse_val))
rmse_results_val %>% knitr::kable(., format = "pipe", padding = 2)
```


**Conclusion:** Movie Bias RMSE: **0.9439087**. When we add movie bias to the equation the RMSE decreases but the model is not yet effective.

 
**Movie and User Bias Model**

From our data exploration we know that some movies are rated more than others, users also affect ratings off the movie. So let us add another bias to the above which is the user Bias <br>

Y u,i = Mu + Movie Bias + User Bias + E u,i <br>
where  <br>
Y u,i is the predicted rating  <br>
E u,i = independent errors centered at 0 <br>
Mu = Average Rating <br>


Create a prediction: <br>


```{r warning=FALSE}

movieUserBias_val <- edx %>% left_join(movieBias_val, by = "movieId") %>% group_by(userId) %>%
  summarize(mean_rating_m_u_val= mean(rating - mean_validation_mu - mean_rating_m_val))


# Create the Prediction
prediction_mov_usr_eff_val <-validation %>% left_join(movieBias_val, by = "movieId") %>%
  left_join(movieUserBias_val, by = "userId") %>%
  mutate(predictions = mean_validation_mu + mean_rating_m_val + mean_rating_m_u_val) %>% .$predictions
movie_usr_rmse_val <-RMSE(validation$rating, prediction_mov_usr_eff_val)
movie_usr_rmse_val

```

```{r warning=FALSE}
## Save Results in Data Frame
rmse_results_val <- bind_rows(rmse_results_val, 
                          data_frame(Method="Analysis By Movie  & User Bias",
                                     ValidationSet_RMSE = movie_usr_rmse_val))
rmse_results_val %>% knitr::kable(., format = "pipe", padding = 2)
```


**Conclusion:** Movie and User Bias RMSE : **0.8653488**

**Movie , User and Age off Movie Bias Model**

Now let us introduce movie age to the above. This is the movie age bias where the more the number of years the more the number of ratings  <br>

Y u,i = Mu + Movie Bias + User Bias + Movie Age Bias + E u,i<br>
where <br>
Y u,i is the predicted rating <br>
E u,i = independent errors centered at 0<br>
Mu = Average Rating<br>


Create a prediction:

```{r warning=FALSE}

movieUserAgeBias_val <- edx %>% left_join(movieBias_val, by = "movieId") %>% left_join(movieUserBias_val, by = "userId") %>%
  group_by(age_of_movie) %>% 
  summarize(mean_rating_m_u_a_val = mean(rating - mean_rating_m_u_val - mean_rating_m_val - mean_validation_mu ))


# Create the Prediction
prediction_mov_usr_mage_eff_val <-validation %>% left_join(movieBias_val, by = "movieId") %>%
  left_join(movieUserBias_val, by = "userId") %>% left_join(movieUserAgeBias_val, by = "age_of_movie") %>%
  mutate(predictions = mean_validation_mu + mean_rating_m_val + mean_rating_m_u_val  + mean_rating_m_u_a_val) %>% .$predictions
movie_usr_mage_rmse_val <-RMSE(validation$rating, prediction_mov_usr_mage_eff_val)
movie_usr_mage_rmse_val

```

```{r warning=FALSE}
## Save Results in Data Frame

rmse_results_val <- bind_rows(rmse_results_val, 
                          data_frame(Method="Analysis By Movie, User & Movie Age Bias",
                                     ValidationSet_RMSE = movie_usr_mage_rmse_val))
rmse_results_val %>% knitr::kable(., format = "pipe", padding = 2)
```

**Conclusion:** Movie User and Age of Movie Bias RMSE: **0.8650043**


**Movie & User Bias Model with Regularization**

Adding a tuning parameter lambda to the model

```{r message=FALSE,warning=FALSE}

lambdaval <- seq(0, 10, 0.25)
rmses <- sapply(lambdaval, function(l){
  
  edx_mu <- mean(edx$rating)
  
  movie_bias_i_val <- edx %>%
    group_by(movieId) %>%
    summarise(movie_bias_i_val = sum(rating - edx_mu)/(n()+l))
  
  user_bias_u_val <- edx %>%
    left_join(movie_bias_i_val, by="movieId") %>%
    group_by(userId) %>%
    summarise(user_bias_u_val = sum(rating - movie_bias_i_val - edx_mu)/(n()+l))
  
  predicted_ratings_val <- validation %>%
    left_join(movie_bias_i_val, by = "movieId") %>%
    left_join(user_bias_u_val, by = "userId") %>%
    mutate(predictions = edx_mu + movie_bias_i_val + user_bias_u_val) %>%.$predictions
  
  
  return(RMSE(predicted_ratings_val, validation$rating))
})

```

```{r warning=FALSE}

qplot(lambdaval, rmses)  
rmse_regularisation_val <- min(rmses)
rmse_regularisation_val

```


```{r warning=FALSE}
## Save Results in Data Frame

rmse_results_val <- bind_rows(rmse_results_val, 
                          data_frame(Method="Movie and User Effect with Regularization",
                                     ValidationSet_RMSE = rmse_regularisation_val))
rmse_results_val %>% knitr::kable(., format = "pipe", padding = 2)
```


**Conclusion:** Movie and User Bias RMSE with regularization results in : **0.864817**

# Results and Inference
Our final model has resulted in an RMSE of 0.86481 which is below the targeted RMSE of **0.8775**. The final model we derived was the Movie and User Effect with Regularization. We have seen that the movie, users bias are factors that contribute to the ratings heavily. Age is also a factor, but we saw that the RMSE decreased but not by a lot.

```{r warning=FALSE}
## Save Results in Data Frame

rmse_results %>% knitr::kable(., format = "pipe", padding = 2)

rmse_results_val %>% knitr::kable(., format = "pipe", padding = 2)

```

There will be other biases that could impact the ratings e.g., geography, actors, etc. We have not explored all the biases in the dataset but started off with a few. There will also be other methods of modeling that would help us achieve a lower RMSE.
 
